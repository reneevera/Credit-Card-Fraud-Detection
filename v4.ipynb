{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from imblearn.over_sampling import ADASYN\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.ensemble import RandomForestClassifier, VotingClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import roc_curve, auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and explore the dataset\n",
    "df = pd.read_csv('/creditcard.csv')\n",
    "print(\"Rows & Columns:\\n\", df.shape)\n",
    "print(\"\\nColumn Names:\\n\", list(df.columns))\n",
    "print(\"\\nColumn Names and data types\\n\", df.dtypes)\n",
    "print(\"0 = Normal Transaction, 1 = Fraud\\n\\n\", df['Class'].value_counts())\n",
    "print(round(df['Class'].value_counts()[0]/len(df) * 100,2), '% of the dataset are normal transactions')\n",
    "print(round(df['Class'].value_counts()[1]/len(df) * 100,2), '% of the dataset are fraud transactions')\n",
    "print(\"Missing Values in Dataset: \", df.isnull().sum().max())\n",
    "print(\"Stats:\\n\", df.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scaling 'Time' and 'Amount' using RobustScaler to reduce the impact of outliers\n",
    "df['scaled_amount'] = RobustScaler().fit_transform(df['Amount'].values.reshape(-1,1))\n",
    "df['scaled_time'] = RobustScaler().fit_transform(df['Time'].values.reshape(-1,1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the original 'Time' and 'Amount' columns and move the scaled versions to the first columns\n",
    "df.drop(['Time', 'Amount'], axis=1, inplace=True)\n",
    "df.insert(0, 'scaled_time', df.pop('scaled_time'))\n",
    "df.insert(1, 'scaled_amount', df.pop('scaled_amount'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the dataset with updated features\n",
    "sns.boxplot(x='Class', y='scaled_amount', data=df)\n",
    "plt.title('Distribution of Scaled Transaction Amounts by Class')\n",
    "plt.ylim(-5, 20)\n",
    "plt.xticks([0, 1], ['Normal', 'Fraud'])\n",
    "plt.xlabel('Class')\n",
    "plt.ylabel('Scaled Amount')\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.hist(df['scaled_time'], bins=50, alpha=0.7)\n",
    "plt.xlabel('Scaled Transaction Time')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Distribution of Scaled Transaction Time')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handle class imbalance using ADASYN\n",
    "X = df.drop('Class', axis=1)\n",
    "y = df['Class']\n",
    "adasyn = ADASYN(random_state=42)\n",
    "X_resampled, y_resampled = adasyn.fit_resample(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and testing sets\n",
    "train_X, test_X, train_y, test_y = train_test_split(X_resampled, y_resampled, test_size=0.3, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature selection with the resampled dataset\n",
    "selector = SelectKBest(f_classif, k=10)\n",
    "train_X_new = selector.fit_transform(train_X, train_y)\n",
    "best_features_indices = selector.get_support(indices=True)\n",
    "print(\"Selected Features Indices:\", best_features_indices)\n",
    "train_X = pd.DataFrame(train_X_new, columns=train_X.columns[best_features_indices])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature scaling\n",
    "pipeline = Pipeline([\n",
    "    ('scaling', StandardScaler())\n",
    "])\n",
    "pipeline.fit(train_X)\n",
    "test_X_selected = pd.DataFrame(selector.transform(test_X), columns=train_X.columns)\n",
    "test_X = pipeline.transform(test_X_selected)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logistic Regression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "linear_clf = LogisticRegression()\n",
    "linear_clf.fit(train_X, train_y)\n",
    "linear_predictions = linear_clf.predict(test_X)\n",
    "print(\"Linear Classifier - Classification Report\")\n",
    "print(classification_report(test_y, linear_predictions))\n",
    "print(\"Confusion Matrix\")\n",
    "print(confusion_matrix(test_y, linear_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fine-tune Logistic Regression\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "param_grid = {\n",
    "    'C': [0.001, 0.01, 0.1, 1, 10, 100],\n",
    "    'penalty': ['l1', 'l2'],\n",
    "    'solver': ['liblinear']\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(estimator=LogisticRegression(), param_grid=param_grid, cv=5, scoring='f1')\n",
    "grid_search.fit(train_X, train_y)\n",
    "print(\"Best Parameters:\", grid_search.best_params_)\n",
    "print(\"Best F1-Score:\", grid_search.best_score_)\n",
    "\n",
    "best_params = {\n",
    "    'C': 0.001,\n",
    "    'penalty': 'l2',\n",
    "    'solver': 'liblinear'\n",
    "}\n",
    "linear_clf = LogisticRegression(**best_params)\n",
    "linear_clf.fit(train_X, train_y)\n",
    "linear_predictions = linear_clf.predict(test_X)\n",
    "print(\"Linear Classifier - Classification Report\")\n",
    "print(classification_report(test_y, linear_predictions))\n",
    "print(\"Confusion Matrix\")\n",
    "print(confusion_matrix(test_y, linear_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ROC curve for Logistic Regression\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "y_scores = linear_clf.predict_proba(test_X)[:, 1]\n",
    "fpr, tpr, _ = roc_curve(test_y, y_scores)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(fpr, tpr, color='blue', lw=2, label='ROC curve (AUC = %0.2f)' % roc_auc)\n",
    "plt.plot([0, 1], [0, 1], color='red', linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver Operating Characteristic (ROC)')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Support Vector Machine (SVM)\n",
    "from sklearn.svm import SVC\n",
    "svm = SVC(probability=True)\n",
    "svm.fit(train_X, train_y)\n",
    "svm_predictions = svm.predict(test_X)\n",
    "print(\"SVM - Classification Report\")\n",
    "print(classification_report(test_y, svm_predictions))\n",
    "print(\"Confusion Matrix\")\n",
    "print(confusion_matrix(test_y, svm_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fine-tune SVM\n",
    "param_grid = {\n",
    "    'C': [0.1, 1, 10, 100],\n",
    "    'gamma': [0.001, 0.01, 0.1, 1],\n",
    "    'kernel': ['linear', 'rbf']\n",
    "}\n",
    "grid_search_svm = GridSearchCV(estimator=SVC(), param_grid=param_grid, cv=5, scoring='f1')\n",
    "grid_search_svm.fit(train_X, train_y)\n",
    "print(\"Best Parameters:\", grid_search_svm.best_params_)\n",
    "print(\"Best F1-Score:\", grid_search_svm.best_score_)\n",
    "\n",
    "svm_tuned = SVC(kernel='rbf', C=100, gamma=0.1,probability=True)\n",
    "cv_scores = cross_val_score(svm_tuned, train_X, train_y, cv=5, scoring='accuracy')\n",
    "print(\"Cross-validation scores:\", cv_scores)\n",
    "print(\"Mean CV accuracy:\", cv_scores.mean())\n",
    "svm_tuned.fit(train_X, train_y)\n",
    "svm_predictions = svm_tuned.predict(test_X)\n",
    "print(\"RBF Kernel SVM - Classification Report\")\n",
    "print(classification_report(test_y, svm_predictions))\n",
    "print(\"Confusion Matrix\")\n",
    "print(confusion_matrix(test_y, svm_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ROC curve for SVM\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "y_scores_cv = cross_val_predict(svm_tuned, train_X, train_y, cv=5, method=\"decision_function\")\n",
    "fpr, tpr, thresholds = roc_curve(train_y, y_scores_cv)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(fpr, tpr, color='blue', lw=2, label='ROC curve (AUC = %0.2f)' % roc_auc)\n",
    "plt.plot([0, 1], [0, 1], color='red', linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver Operating Characteristic (ROC)')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decision Tree Classifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "decision_tree = DecisionTreeClassifier(random_state=42)\n",
    "decision_tree.fit(train_X, train_y)\n",
    "decision_tree_predictions = decision_tree.predict(test_X)\n",
    "decision_tree_report = classification_report(test_y, decision_tree_predictions)\n",
    "decision_tree_cm = confusion_matrix(test_y, decision_tree_predictions)\n",
    "print(\"Decision Tree - Classification Report\")\n",
    "print(decision_tree_report)\n",
    "print(\"Confusion Matrix\")\n",
    "print(decision_tree_cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fine-tune Decision Tree\n",
    "from warnings import simplefilter\n",
    "simplefilter(action='ignore', category=FutureWarning)\n",
    "param_grid_decision_tree = {\n",
    "    'criterion': ['entropy'],\n",
    "    'max_depth': [None, 5, 10, 15],\n",
    "    'min_samples_split': [5, 10, 15, 20],\n",
    "    'min_samples_leaf': [1, 2, 3],\n",
    "    'max_features': ['auto', 'sqrt', 'log2', None]\n",
    "}\n",
    "grid_search_decision_tree = GridSearchCV(estimator=DecisionTreeClassifier(random_state=42), param_grid=param_grid_decision_tree, cv=5, scoring='f1')\n",
    "grid_search_decision_tree.fit(train_X, train_y)\n",
    "print(\"Best Parameters:\", grid_search_decision_tree.best_params_)\n",
    "print(\"Best F1-Score:\", grid_search_decision_tree.best_score_)\n",
    "\n",
    "decision_tree = DecisionTreeClassifier(criterion='entropy',\n",
    "                                       max_depth=None,\n",
    "                                       max_features=None,\n",
    "                                       min_samples_leaf=3,\n",
    "                                       min_samples_split=5,\n",
    "                                       random_state=42)\n",
    "decision_tree.fit(train_X, train_y)\n",
    "decision_tree_predictions = decision_tree.predict(test_X)\n",
    "decision_tree_report = classification_report(test_y, decision_tree_predictions)\n",
    "decision_tree_cm = confusion_matrix(test_y, decision_tree_predictions)\n",
    "print(\"Decision Tree - Classification Report\")\n",
    "print(decision_tree_report)\n",
    "print(\"Confusion Matrix\")\n",
    "print(decision_tree_cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ROC curve for Decision Tree\n",
    "y_scores = decision_tree.predict_proba(test_X)[:, 1]\n",
    "fpr, tpr, thresholds = roc_curve(test_y, y_scores)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(fpr, tpr, color='blue', lw=2, label='ROC curve (AUC = %0.2f)' % roc_auc)\n",
    "plt.plot([0, 1], [0, 1], color='red', linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver Operating Characteristic (ROC) - Decision Tree')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Forest Classifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "random_forest = RandomForestClassifier(random_state=42)\n",
    "random_forest.fit(train_X, train_y)\n",
    "rf_predictions = random_forest.predict(test_X)\n",
    "print(\"Random Forest - Classification Report\")\n",
    "print(classification_report(test_y, rf_predictions))\n",
    "print(\"Confusion Matrix\")\n",
    "print(confusion_matrix(test_y, rf_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fine-tune Random Forest\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from scipy.stats import randint\n",
    "param_grid_random_forest = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'criterion': ['gini', 'entropy'],\n",
    "    'max_depth': [None, 5, 10, 20],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4],\n",
    "    'max_features': ['auto', 'sqrt', 'log2']\n",
    "}\n",
    "grid_search_random_forest = RandomizedSearchCV(estimator=RandomForestClassifier(random_state=42), param_distributions=param_grid_random_forest, n_iter=50, cv=5, scoring='f1')\n",
    "grid_search_random_forest.fit(train_X, train_y)\n",
    "print(\"Best Parameters:\", grid_search_random_forest.best_params_)\n",
    "print(\"Best F1-Score:\", grid_search_random_forest.best_score_)\n",
    "\n",
    "best_params = {'n_estimators': 300, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_features': 'sqrt', 'max_depth': None, 'criterion': 'entropy'}\n",
    "random_forest = RandomForestClassifier(**best_params)\n",
    "random_forest.fit(train_X, train_y)\n",
    "rf_predictions = random_forest.predict(test_X)\n",
    "print(\"Random Forest - Classification Report\")\n",
    "print(classification_report(test_y, rf_predictions))\n",
    "print(\"Confusion Matrix\")\n",
    "print(confusion_matrix(test_y, rf_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ROC curve for Random Forest\n",
    "y_scores = random_forest.predict_proba(test_X)[:, 1]\n",
    "fpr, tpr, thresholds = roc_curve(test_y, y_scores)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(fpr, tpr, color='blue', lw=2, label='ROC curve (AUC = %0.2f)' % roc_auc)\n",
    "plt.plot([0, 1], [0, 1], color='red', linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver Operating Characteristic (ROC) - Random Forest')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Voting Classifier\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "svm = SVC(kernel='rbf', probability=True)\n",
    "voting_clf = VotingClassifier(estimators=[\n",
    "    ('rbf_svm', svm_tuned),\n",
    "    ('dt', decision_tree),\n",
    "    ('rf', random_forest)],\n",
    "    voting='soft')\n",
    "voting_clf.fit(train_X, train_y)\n",
    "voting_predictions = voting_clf.predict(test_X)\n",
    "print(\"Voting Classifier (soft Voting) - Classification Report\")\n",
    "print(classification_report(test_y, voting_predictions))\n",
    "print(\"Confusion Matrix\")\n",
    "print(confusion_matrix(test_y, voting_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ROC curve for Voting Classifier\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "y_scores = voting_clf.predict_proba(test_X)[:, 1]\n",
    "fpr, tpr, thresholds = roc_curve(test_y, y_scores)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(fpr, tpr, color='blue', lw=2, label='ROC curve (AUC = %0.2f)' % roc_auc)\n",
    "plt.plot([0, 1], [0, 1], color='red', linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver Operating Characteristic (ROC) - Voting Classifier')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
